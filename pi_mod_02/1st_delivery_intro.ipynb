{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a91240",
   "metadata": {},
   "source": [
    "# ENTREGABLE 1\n",
    "\n",
    "## 1. Configuración del entorno de trabajo\n",
    "\n",
    "### Consigna\n",
    "\n",
    "- Instalar y configurar un sistema de gestión de bases de datos relacional (PostgreSQL o SQL Server).\n",
    "- Crear una base de datos de trabajo y preparar el entorno para futuras transformaciones (conexión desde Python vía ORM recomendado).\n",
    "\n",
    "### Detalle de implementación\n",
    "\n",
    "Se configuró un entorno de base de datos con Docker utilizando **PostgreSQL**. Este servicio ejecuta PostgreSQL y monta los scripts SQL necesarios para crear las tablas al iniciar. Además, se incluye **Adminer** para gestionar la base de datos de forma gráfica.\n",
    "\n",
    "El entorno está listo para interactuar con la base de datos desde Python usando **SQLAlchemy** como ORM, lo que facilita la implementación de futuras transformaciones y expansiones del proyecto.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Carga inicial de datos\n",
    "\n",
    "### Consigna\n",
    "\n",
    "- Crear tablas e importar datos a partir de los archivos CSV proporcionados.\n",
    "- Ajustar los tipos de datos según corresponda para preservar la integridad semántica y evitar errores de procesamiento.\n",
    "\n",
    "### Detalle de implementación\n",
    "\n",
    "La implementación se realizó en **dos fases**:\n",
    "\n",
    "### Fase 1: Creación de modelos de tablas e importación de datos\n",
    "\n",
    "Se crearon modelos de tablas basados en las estructuras de los scripts SQL provistos. En esta fase inicial, no se aplicaron restricciones complejas, sino que se enfocó en asegurar la correcta relación entre tablas mediante claves foráneas y los tipos de datos básicos. El objetivo fue importar los datos desde los archivos CSV y asegurar que las claves foráneas (relación entre tablas) estuvieran correctamente configuradas.\n",
    "\n",
    "**Ejemplo de implementación:**\n",
    "\n",
    "```python\n",
    "class Product(BaseModel):\n",
    "\n",
    "    __tablename__ = TableNames.PRODUCTS\n",
    "\n",
    "    product_id: Mapped[int] = mapped_column(ProductColumns.PRODUCT_ID, primary_key=True)\n",
    "    name: Mapped[str] = mapped_column(ProductColumns.NAME, String)\n",
    "    description: Mapped[str] = mapped_column(ProductColumns.DESCRIPTION, String)\n",
    "    price: Mapped[Decimal] = mapped_column(ProductColumns.PRICE, Numeric)\n",
    "    stock: Mapped[int] = mapped_column(ProductColumns.STOCK, Integer)\n",
    "    category_id: Mapped[int] = mapped_column(\n",
    "        CategoryColumns.CATEGORY_ID, ForeignKey(\"Categorias.CategoriaID\"), nullable=False\n",
    "    )\n",
    "    category: Mapped[\"Category\"] = relationship(\"Category\", backref=\"products\")\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, data: dict):\n",
    "        return cls(\n",
    "            product_id=data.get(\"product_id\"),\n",
    "            name=data.get(\"name\", \"\").strip(),\n",
    "            description=data.get(\"description\", \"\").strip(),\n",
    "            price=Decimal(data.get(\"price\", 0)),\n",
    "            stock=data.get(\"stock\", 0),\n",
    "            category_id=data.get(\"category_id\"),\n",
    "        )\n",
    "```\n",
    "### Fase  2: Ajustes de tipos de datos y restricciones de integridad\n",
    "\n",
    "Una vez que los datos fueron importados correctamente, se modificaron los modelos para asegurar la integridad semántica de los datos. Esto incluyó:\n",
    "\n",
    "- Ajuste de tipos de datos: Se cambiaron algunas columnas para asegurar que almacenaran los datos en el tipo adecuado (por ejemplo, fechas o cadenas con longitud fija).\n",
    "\n",
    "- Aplicación de restricciones de integridad: Se añadieron restricciones como CHECK y UNIQUE para evitar que los datos violaran las reglas de negocio. Esto garantiza que los datos sean válidos y coherentes con las expectativas del sistema.\n",
    "\n",
    "**Ejemplo de implementación final (con restricciones):**\n",
    "\n",
    "```python\n",
    "\n",
    "\n",
    "class Product(BaseModel):\n",
    "\n",
    "    __tablename__ = TableNames.PRODUCTS\n",
    "\n",
    "    __table_args__ = (\n",
    "        CheckConstraint(\n",
    "            f\"{ProductColumns.STOCK} >= 0\", name=\"stock_non_negative\"),\n",
    "        CheckConstraint(\n",
    "            f\"{ProductColumns.PRICE} >= 0\", name=\"price_non_negative\"),\n",
    "    )\n",
    "\n",
    "    product_id: Mapped[int] = mapped_column(\n",
    "        ProductColumns.PRODUCT_ID, primary_key=True)\n",
    "    name: Mapped[str] = mapped_column(ProductColumns.NAME, String(255))\n",
    "    description: Mapped[str] = mapped_column(\n",
    "        ProductColumns.DESCRIPTION, String)\n",
    "    price: Mapped[Decimal] = mapped_column(ProductColumns.PRICE, Numeric)\n",
    "    stock: Mapped[int] = mapped_column(ProductColumns.STOCK, Integer)\n",
    "    category_id: Mapped[int] = mapped_column(\n",
    "        CategoryColumns.CATEGORY_ID,\n",
    "        ForeignKey(\"Categorias.CategoriaID\"),\n",
    "        nullable=False,\n",
    "    )\n",
    "    category: Mapped[\"Category\"] = relationship(\"Category\", backref=\"products\")\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, data: dict):\n",
    "        return cls(\n",
    "            product_id=data.get(\"product_id\"),\n",
    "            name=data.get(\"name\", \"\").strip(),\n",
    "            description=data.get(\"description\", \"\").strip(),\n",
    "            price=Decimal(data.get(\"price\", 0)),\n",
    "            stock=data.get(\"stock\", 0),\n",
    "            category_id=data.get(\"category_id\"),\n",
    "        )\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Tratamiento de campos semi-estructurados\n",
    "\n",
    "\n",
    "### Consigna\n",
    "\n",
    "- Identificar columnas que contengan datos en formatos como JSON, listas, o concatenaciones delimitadas.\n",
    "\n",
    "- Aplicar técnicas de limpieza y transformación para estructurar adecuadamente la información.\n",
    "\n",
    "\n",
    "### Identificación de columnas con datos semiestructurados\n",
    "\n",
    "| **Tabla.Columna**               | **Descripción y ejemplo**                                                       | **Decisión de transformación**                                                                                                                                                       |\n",
    "|----------------------------------|---------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Categorias.Descripción**       | Es una descripción con ejemplos de la misma separados por comas, ej: 'Teléfonos, computadoras, accesorios y dispositivos inteligentes' | No se normaliza, dado que parece una descripción y las preguntas de negocio no requieren ese nivel de detalle. Mantiene su formato como texto.                                        |\n",
    "| **MetodosPago.Descripcion**     | Caso similar al de `Categorias.Descripción`, ej: 'Pago con tarjeta de crédito VISA, MasterCard o American Express'                  | No se aplicó transformación, dado que no se requiere conocer marcas de tarjetas, solo la modalidad de pago (ej., 'Tarjeta de Crédito', 'Transferencia Bancaria').                   |\n",
    "\n",
    "---\n",
    "\n",
    "## 4.Análisis exploratorio y evaluación de calidad de datos\n",
    "\n",
    "### Consigna\n",
    "\n",
    "\n",
    "- Explorar la estructura y el contenido de los datos utilizando consultas SQL.\n",
    "\n",
    "- Implementar análisis exploratorio complementario en Python mediante un ORM (como SQLAlchemy o psycopg2).\n",
    "\n",
    "- Detectar valores nulos, duplicados, atípicos y otras inconsistencias.\n",
    "\n",
    "- Identificar claves primarias y foráneas implícitas, atributos principales y variables relevantes para el negocio.\n",
    "\n",
    "- Proponer y documentar acciones de preprocesamiento y corrección de calidad de datos.\n",
    "\n",
    "### Desarrollo de consignas \n",
    "\n",
    "#### 1. Explorar la estructura y el contenido de los datos utilizando consultas SQL\n",
    "En esta fase del análisis, el objetivo principal es obtener una comprensión detallada sobre la estructura y el contenido de las tablas dentro de la base de datos, así como la naturaleza de los datos. Este paso es fundamental porque nos permite identificar las relaciones entre las tablas, la calidad de los datos, y cualquier posible inconsistencia que pueda requerir correcciones antes de realizar análisis más avanzados.\n",
    "\n",
    "\n",
    "- Consultas de exploración\n",
    "\n",
    "Consulta para identificar tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac441e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.utils import postgres_utils\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT table_name\n",
    "FROM information_schema.tables\n",
    "WHERE table_schema = 'public';\n",
    "\"\"\"\n",
    "tables = postgres_utils.run_query(query)\n",
    "\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16d8d67",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "* Consulta de la estructura de las tablas , para conocer columnas y tipos de datos de las mismas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f57dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from app.utils import postgres_utils\n",
    "\n",
    "query_tables_structure = \"\"\"\n",
    "        SELECT table_name, column_name, data_type\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = 'public'\n",
    "        ORDER BY table_name, ordinal_position;\n",
    "    \"\"\"\n",
    "\n",
    "postgres_utils.run_query(query_tables_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b89f4a0",
   "metadata": {},
   "source": [
    "Consulta para obtener primeros registros de cada tabla, para explorar los datos y formatos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba68f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.utils import postgres_utils\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"sqlalchemy.engine\").setLevel(logging.WARNING)\n",
    "\n",
    "def get_first_records(table_name):\n",
    "    query = f\"SELECT * FROM \\\"{table_name}\\\" LIMIT 10;\"\n",
    "    data = postgres_utils.run_query(query)\n",
    "    return data\n",
    "\n",
    "tables_list = tables['table_name'].unique()\n",
    "for table in tables_list:\n",
    "    data= postgres_utils.run_query(f\"SELECT * FROM \\\"{table}\\\" LIMIT 5;\")\n",
    "    display(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4638313",
   "metadata": {},
   "source": [
    "## 2.Implementar análisis exploratorio complementario en Python mediante un ORM (como SQLAlchemy o psycopg2).\n",
    "\n",
    "En [Archivo Entrega 1](1st_delivery.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
